---
title: "Test results for SAGA project in GSoC 2018"
author: "Johan Larsson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{GSoC 2018 SAGA project test results}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev.args = list(pointsize = 8)
)
```

## Easy

Our first task is to fit a L1-regularized linear model to the spam data set
from **ElemStatLearn** and analyze the results in terms of the selected
features as well as test error and AUC. We will also compare our model to a
naive model that predicts the most frequent class.

We begin by loading our libraries.

```{r libraries}
library(glmnet)
library(ElemStatLearn)
```

Next, we set up simple train and test partitions.

```{r train}
# extract the necessary data
x <- as.matrix(spam[, -ncol(spam)])
y <- spam$spam
n <- nrow(x)

# create train and test sets
train_id <- sample(seq_len(n), size = floor(0.8*n))
train_x <- x[train_id, ]
train_y <- y[train_id]
test_x <- x[-train_id, ]
test_y <- y[-train_id]

# train the model
fit1 <- cv.glmnet(train_x, train_y, family = "binomial")
```

The model's chosen factors are

```{r features}
names(coef(fit1)[coef(fit1)[, 1] > 0, ])
```

Now we will study the performance of the model. We are going to use 
Receiver Operating Characteristics of the model as well as a 
naive classification scheme wherein each observation is classified
as the most prevalent category in the training set, namely
``r names(which.max(table(train_y)))``.

```{r roc, fig.cap = "Receiver operating characteristic curves for the lasso model (to the left) and naive model (to the right)."}
library(pROC)

roc1 <- roc(test_y, as.vector(predict(fit1, test_x, type = "response")),
            ci = TRUE)
roc2 <- roc(test_y, rep(1, length(test_y)), ci = TRUE)
par(mfrow = c(1, 2))
plot(roc1)
plot(roc2)
```

The 95% confidence level for the Area Under the Curve (AUC) value for our
lasso model is $[`r roc1$ci[1]`, `r roc1$ci[3]`]$, which
is signficantly better than that of our naive predictions, which of course
are 0.5 (with no variance).

## Medium

In this part we are going to measure the performance of **glmnet** with
that of **bigoptim** using **microbenchmark**. For this purpose,
we are going to use the `covtype.libsvm` dataset from **bigoptim**
and see how the timings differ across numbers of columns and rows in the
data.


Looking at the results from the simulation, we note that `glmnet()`
converges when either the number of rows or columns are relatively low.
As we add more observations (rows) or covariates (columns), however,
the performance of the SAG algorithm.

```{r, fig.cap = "Logarithmized timings of GLMnet and SAG runs."}
gradpal <- colorRampPalette(RColorBrewer::brewer.pal(11, "Spectral"))(100)
lattice::levelplot(
  log(time) ~ cols*rows | package, 
  data = data_medium,
  col.regions = gradpal
)
```

```{r, fig.cap = "Loss"}
lattice::levelplot(
  loss ~ cols*rows | package,
  data = data_medium,
  col.regions = gradpal
)
```


## Medium-hard


```{r, fig.cap = "Logarithmized timings of GLMnet and SAG runs."}
lattice::levelplot(
  log(time) ~ cols*rows | package, 
  data = data_mediumhard,
  col.regions = gradpal
)
```

```{r, fig.cap = "Loss"}
lattice::levelplot(
  loss ~ cols*rows | package,
  data = data_mediumhard,
  col.regions = gradpal
)
```
